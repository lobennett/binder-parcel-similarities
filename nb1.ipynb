{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ef8da47",
   "metadata": {},
   "source": [
    "---\n",
    "## HDF5 File Downloaded from Google Drive\n",
    "\n",
    "To interactively view the file, I recommend using the HDF5 viewer found at [https://myhdf5.hdfgroup.org/](https://myhdf5.hdfgroup.org/).\n",
    "\n",
    "**File structure summary:**\n",
    "\n",
    "- **Root (`/`)**\n",
    "  - **Attributes**: Contains global mean similarity scores (`mean_within_subject_similarity`, `mean_between_subject_similarity`, etc.).\n",
    "  - **Groups**: Each group corresponds to an fMRI contrast.\n",
    "\n",
    "- **`/{contrast_name}`** (e.g., `/task-nBack_contrast-twoBack-oneBack/`)\n",
    "  - **Groups**: Contains a subgroup for each brain parcel from the Schaefer atlas.\n",
    "\n",
    "- **`/{contrast_name}/{parcel_name}`** (e.g., `/task-nBack_contrast-twoBack-oneBack/7Networks_LH_Cont_Cing_1`)\n",
    "  - **Attributes**: Stores calculated similarity scores for this specific contrast-parcel pair (`within_subject_similarity`, `between_subject_similarity`, `across_construct_similarity_*`).\n",
    "  - **Datasets**: Contains individual datasets for each subject's session.\n",
    "\n",
    "- **`/{contrast_name}/{parcel_name}/{record_name}`** (e.g., `/task-nBack_contrast-twoBack-oneBack/7Networks_LH_Cont_Cing_1/sub-s03_ses-02_run-1`)\n",
    "  - **Data**: `voxel_values` (a 1D array of beta values from the contrast map).\n",
    "  - **Attributes**: `subject`, `session`, `mean_voxel_value` (e.g., `'sub-s03'`, `'ses-02'`, '`0.9296506904112123`').\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491b2140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import os\n",
    "\n",
    "# Define the files to download from Google Drive\n",
    "files_to_download = [\n",
    "    {\n",
    "        \"file_id\": \"1dJNXrzTr-92p9R2mxFzE9V-R8nWUvvAt\",\n",
    "        \"filename\": \"./data/all_contrasts.h5\",\n",
    "        \"description\": \"Parcel similarity results for all contrasts\",\n",
    "    },\n",
    "]\n",
    "\n",
    "for file_info in files_to_download:\n",
    "    file_id = file_info[\"file_id\"]\n",
    "    filename = file_info[\"filename\"]\n",
    "    description = file_info.get(\"description\", filename)\n",
    "    if not os.path.exists(filename):\n",
    "        print(f\"Give this some time...\")\n",
    "        gdown.download(id=file_id, output=filename, quiet=False)\n",
    "        print(f\"File downloaded: {filename}\")\n",
    "    else:\n",
    "        print(f\"File already exists: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9485b517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def clean_print_dict(d, indent=2, key_width=32):\n",
    "    \"\"\"Pretty prints a dictionary with aligned keys and compact values.\"\"\"\n",
    "    for k, v in d.items():\n",
    "        # Handle potential arrays in attributes by showing a summary\n",
    "        if isinstance(v, (np.ndarray, list)):\n",
    "            v_arr = np.array(v)\n",
    "            if v_arr.size > 10:\n",
    "                v = f\"Array(shape={v_arr.shape}, dtype={v_arr.dtype})\"\n",
    "        print(\" \" * indent + f\"{str(k):<{key_width}}: {v}\")\n",
    "\n",
    "\n",
    "def inspect_metadata(\n",
    "    hdf5_path: Path, num_contrasts: int, num_parcels: int, num_records: int, num_voxels: int\n",
    "):\n",
    "    \"\"\"\n",
    "    Opens the HDF5 file and prints metadata with clean, readable formatting.\n",
    "    Shows the first `num_records` records for each parcel, including their voxel values and attributes.\n",
    "    \"\"\"\n",
    "    if not hdf5_path.is_file():\n",
    "        print(f\"Error: File not found at '{hdf5_path}'\")\n",
    "        return\n",
    "\n",
    "    # Header for clear separation in terminal output\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\" Inspecting HDF5 File: {hdf5_path.name} \".center(80, \"=\"))\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    try:\n",
    "        with h5py.File(hdf5_path, \"r\") as f:\n",
    "            # Display global attributes at the root level\n",
    "            if f.attrs:\n",
    "                print(\"\\nGlobal File Attributes:\")\n",
    "                clean_print_dict(dict(f.attrs), indent=2, key_width=32)\n",
    "\n",
    "            contrast_keys = sorted(f.keys())\n",
    "            print(f'\\nThere are {len(contrast_keys)} contrasts in this file. The first {num_contrasts} are:')\n",
    "            for contrast_name in contrast_keys[:num_contrasts]:\n",
    "                print(f\"- {contrast_name}\")\n",
    "\n",
    "            for contrast_name in contrast_keys[:num_contrasts]:\n",
    "                print(\"\\n\" + \"-\" * 80)\n",
    "                print(f\"[Contrast] {contrast_name}\")\n",
    "                contrast_group = f[contrast_name]\n",
    "\n",
    "                parcel_keys = sorted(contrast_group.keys())\n",
    "                for parcel_name in parcel_keys[:num_parcels]:\n",
    "                    parcel_group = contrast_group[parcel_name]\n",
    "                    print(f\"  [Parcel] {parcel_name}\")\n",
    "\n",
    "                    # Print attributes (metadata) of the parcel\n",
    "                    if parcel_group.attrs:\n",
    "                        print(\"    Attributes:\")\n",
    "                        clean_print_dict(\n",
    "                            dict(parcel_group.attrs), indent=6, key_width=36\n",
    "                        )\n",
    "\n",
    "                    record_keys = sorted(parcel_group.keys())\n",
    "                    total_records = len(record_keys)\n",
    "                    print(f\"    Records: {total_records} contrast files (aka 'records') found.\")\n",
    "\n",
    "                    # Show info for the first `num_records` records\n",
    "                    n_records_to_show = min(num_records, total_records)\n",
    "                    if n_records_to_show == 0:\n",
    "                        continue\n",
    "\n",
    "                    for i, record_name in enumerate(record_keys[:n_records_to_show]):\n",
    "                        record_group = parcel_group[record_name]\n",
    "                        print(f\"    Record {i+1}: '{record_name}'\")\n",
    "                        # Print record attributes (e.g., subject)\n",
    "                        if hasattr(record_group, \"attrs\") and record_group.attrs:\n",
    "                            print(\"      Attributes:\")\n",
    "                            clean_print_dict(\n",
    "                                dict(record_group.attrs), indent=8, key_width=28\n",
    "                            )\n",
    "                        # Print voxel values\n",
    "                        if \"voxel_values\" in record_group:\n",
    "                            voxel_dataset = record_group[\"voxel_values\"]\n",
    "                            n_vox_to_show = min(num_voxels, voxel_dataset.shape[0])\n",
    "                            voxel_preview = voxel_dataset[:n_vox_to_show]\n",
    "                            preview_str = np.array2string(\n",
    "                                voxel_preview,\n",
    "                                precision=3,\n",
    "                                separator=\", \",\n",
    "                                suppress_small=True,\n",
    "                            )\n",
    "                            print(f\"      - Total Voxels: {voxel_dataset.shape[0]}\")\n",
    "                            print(f\"      - Voxel Values (first {n_vox_to_show}):\")\n",
    "                            for line in preview_str.splitlines():\n",
    "                                print(\"        \" + line)\n",
    "                        else:\n",
    "                            print(\"      No 'voxel_values' dataset found in this record.\")\n",
    "\n",
    "    except OSError:\n",
    "        print(\n",
    "            f\"Error: Could not read '{hdf5_path}'. It might not be a valid HDF5 file.\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "\n",
    "hdf5_file, num_contrasts, num_parcels, num_records, num_voxels = Path(\"./data/all_contrasts.h5\"), 2, 2, 2, 10\n",
    "inspect_metadata(hdf5_file, num_contrasts, num_parcels, num_records, num_voxels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
